{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQD_MAIN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohitDhungana/duplicate_question_detection/blob/master/Subin_dQd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZlxkvW__7mI",
        "colab_type": "code",
        "outputId": "42ad557e-7e7f-4cc0-9fcb-e28bbf2a9091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e7OQme1A308",
        "colab_type": "code",
        "outputId": "8cb041a7-bacb-403d-c18d-881db74b5e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "!ls '/content/drive/My Drive'\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Colab Notebooks'\n",
            " Compressed\n",
            "'dogs and cats pic'\n",
            "'energy environment and society  assignment.pdf'\n",
            " image-93b016bfc7ea033589b8766d020d99cb0108180bdaa53d05dbdaf5883674852e-V.jpg\n",
            " kagglecatsanddogs_3367a\n",
            " kagglecatsanddogs_3367a.rar\n",
            " Keygen.exe\n",
            " KIC072BCT039.jpg\n",
            "'New Doc 2019-03-03 12.05.252394441364277969478.pdf'\n",
            " the-new-encyclopedia-of-modern-bodybuilding-arnold.pdf\n",
            " train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVvNDvPLBLDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def text_to_word_list(text):\n",
        "#   gets a whole question inside text variable on which  preprocessing is done and then the question is splitted into word indices and returned\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfmvHK6CBb2v",
        "colab_type": "code",
        "outputId": "81608d28-7194-480c-ae94-dfdd63e32485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Prepare embedding\n",
        "\n",
        "vocabulary = dict() \n",
        "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "word2vec = KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "questions_cols = ['question1', 'question2']\n",
        "\n",
        "# Iterate over the questions(i.e. 'question 1', 'question2') of the training sets provided \n",
        "# get the data from dataset(df) in  variable dataset\n",
        "for dataset in [df]:\n",
        "#   now iterate through the rows of the dataset using  index as iterator (i.e. goes through the row having particular index at a time) \n",
        "    for index, row in dataset.iterrows():\n",
        "\n",
        "        # Iterate through the text of both questions within the current  row\n",
        "        for question in questions_cols:\n",
        "            que2no = []  # que2no ->  numbers representation of the cureently being processed question\n",
        "            \n",
        "            count_ = 0\n",
        "\n",
        "            for word in text_to_word_list(row[question]):\n",
        "\n",
        "                # Check for unwanted words i.e mainly stopwords\n",
        "                if word in stops and word not in word2vec.vocab:\n",
        "                    continue\n",
        "                    \n",
        "#                 limit the length to 50, this decreased the time to train an epoch from more than 1 hour to 20 minutes.\n",
        "                if count_ >= 50 :\n",
        "                  continue\n",
        "                count_ +=1\n",
        "                \n",
        "                \n",
        "                if word not in vocabulary:\n",
        "                    vocabulary[word] = len(inverse_vocabulary)\n",
        "                    que2no.append(len(inverse_vocabulary))\n",
        "                    inverse_vocabulary.append(word)\n",
        "                else:\n",
        "                    que2no.append(vocabulary[word])\n",
        "#                     que2no.append(float(vocabulary[word]))\n",
        "\n",
        "#                 que2no=list(map(int,que2no))\n",
        "\n",
        "            # Replace questions as word to question as number representation\n",
        "            dataset.set_value(index, question, que2no)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPG__4vqCFNI",
        "colab_type": "code",
        "outputId": "1cf77a33-4d84-427c-ad0d-a563803961b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "# max_sequence_length=50\n",
        "max_seq_length = max(df.question1.map(lambda x: len(x)).max(),\n",
        "                     df.question2.map(lambda x: len(x)).max()\n",
        "                    )\n",
        "# max_seq_length\n",
        "df.tail()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>404285</th>\n",
              "      <td>404285</td>\n",
              "      <td>433578</td>\n",
              "      <td>379845</td>\n",
              "      <td>[26, 184, 3632, 115, 307, 8, 3, 24585, 522, 52...</td>\n",
              "      <td>[26, 184, 3632, 115, 307, 8, 12032, 522, 523, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404286</th>\n",
              "      <td>404286</td>\n",
              "      <td>18840</td>\n",
              "      <td>155606</td>\n",
              "      <td>[97, 99, 2441, 307, 2, 598, 180, 1822]</td>\n",
              "      <td>[2, 47, 467, 77, 307, 2, 598, 180, 1822]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404287</th>\n",
              "      <td>404287</td>\n",
              "      <td>537928</td>\n",
              "      <td>537929</td>\n",
              "      <td>[1, 2, 57, 11012]</td>\n",
              "      <td>[1, 2, 83, 11012]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404288</th>\n",
              "      <td>404288</td>\n",
              "      <td>537930</td>\n",
              "      <td>537931</td>\n",
              "      <td>[1, 2, 3, 21205, 12587, 534, 2769, 33, 3114, 8...</td>\n",
              "      <td>[16, 42, 1086, 2877, 2854, 2622, 1220, 16, 173...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404289</th>\n",
              "      <td>404289</td>\n",
              "      <td>537932</td>\n",
              "      <td>537933</td>\n",
              "      <td>[1, 2, 139, 401, 2543, 175, 7227]</td>\n",
              "      <td>[1, 2, 47, 139, 401, 2543, 175, 135, 7227]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...  is_duplicate\n",
              "404285  404285  ...             0\n",
              "404286  404286  ...             1\n",
              "404287  404287  ...             0\n",
              "404288  404288  ...             0\n",
              "404289  404289  ...             0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS30hxt_OvzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "# creating an embedding matrix whose length is one more than vocabulary and dimension is 300\n",
        "embedding_matrix = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  \n",
        "embedding_matrix[0] = 0  # So that the zeroth place remain empty \n",
        "\n",
        "# (Build the embedding matrix) Assigning the word2vec embedding for each words of our vocabulary  \n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embedding_matrix[index] = word2vec.word_vec(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS7KaJt3O2R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del word2vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQX5TXOPQYO",
        "colab_type": "code",
        "outputId": "dba6db0c-c064-4a37-c060-6fa45f816f86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X=df[questions_cols]\n",
        "Y=df['is_duplicate']\n",
        "\n",
        "\n",
        "x_train,x_validate,y_train,y_validate = train_test_split(X, Y, test_size = 0.3) # dataset split to 70% for training and 30% for validation\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_validate.shape)\n",
        "print(y_train.shape)\n",
        "print(y_validate.shape)\n",
        "                 \n",
        "# Split to dicts\n",
        "x_train = {'left': x_train.question1, 'right': x_train.question2}\n",
        "x_validate = {'left': x_validate.question1, 'right': x_validate.question2}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "y_train=y_train.values\n",
        "y_validate=y_validate.values\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(283003, 2)\n",
            "(121287, 2)\n",
            "(283003,)\n",
            "(121287,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZc4-nnYP-dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# zero padding\n",
        "\n",
        "for dataset, side in itertools.product([x_train,x_validate],['left','right']):\n",
        "  dataset[side] = pad_sequences(dataset[side], maxlen = max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgUMIIWPQ3zc",
        "colab_type": "code",
        "outputId": "437a83f7-1c52-4a64-91f3-8de43d761a81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# print(df['question1'][0])\n",
        "\n",
        "# print(dataset)\n",
        "print(x_train['left'].shape)\n",
        "# print(x_train['left'])\n",
        "print(x_validate['left'].shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(283003, 50)\n",
            "(121287, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhNvzgKuQ_nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check to see if shape of left and right input is same\n",
        "assert x_train['left'].shape == x_train['right'].shape\n",
        "\n",
        "# check to see if shape of input and output is same\n",
        "assert len(x_train['left']) == len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ox-AVGRu60",
        "colab_type": "code",
        "outputId": "78045c8d-8703-4140-80db-4cab51cba55e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# shape of question1 column (x,y)==(total rows, total words in each question)\n",
        "x_train['left'].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(283003, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz0P_YedR236",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# manhattan distance calculation function\n",
        "import tensorflow.keras.backend as K\n",
        "def manhattan_distance(left,right):\n",
        "  return K.exp(-K.sum(K.abs(left-right),axis=1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vdeYPxYTicf",
        "colab_type": "code",
        "outputId": "5b5c5c20-0532-45b0-a011-fe64159e791b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda\n",
        "\n",
        "n_hidden = 50\n",
        "n_epochs=2\n",
        "gradient_clipping_norm  = 1.25\n",
        "\n",
        "# input layer\n",
        "#recheck shape before training\n",
        "left_input = Input(shape = (max_seq_length,), dtype='int32',name = 'left_input')\n",
        "right_input = Input(shape = (max_seq_length,), dtype='int32', name = 'right_input')\n",
        "\n",
        "\n",
        "\n",
        "# embedding layer\n",
        "# recheck dims \n",
        "embedding_layer = Embedding(input_dim = len(embedding_matrix), output_dim = embedding_dim, input_length = max_seq_length, weights=[embedding_matrix], trainable=False, name = 'embedding_layer')\n",
        "\n",
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)\n",
        "\n",
        "\n",
        "\n",
        "#LSTM instantiation\n",
        "# check parameter for LSTM.\n",
        "shared_lstm = LSTM(n_hidden, name = 'LSTM_layer')\n",
        "\n",
        "# shared LSTM\n",
        "left_output = shared_lstm(encoded_left)\n",
        "right_output = shared_lstm(encoded_right)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO: check output shape of the output lambda layer\n",
        "# output layer\n",
        "output_layer = Lambda(function = lambda x : manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0],1))([left_output, right_output])\n",
        "\n",
        "\n",
        "\n",
        "# define above model\n",
        "model = tf.keras.Model(inputs=[left_input, right_input], outputs=output_layer)\n",
        "\n",
        "# summary of model\n",
        "print(model.summary())\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "left_input (InputLayer)         [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "right_input (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer (Embedding)     (None, 50, 300)      25796400    left_input[0][0]                 \n",
            "                                                                 right_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_layer (LSTM)               (None, 50)           70200       embedding_layer[0][0]            \n",
            "                                                                 embedding_layer[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_6 (Lambda)               (None, 1)            0           LSTM_layer[0][0]                 \n",
            "                                                                 LSTM_layer[1][0]                 \n",
            "==================================================================================================\n",
            "Total params: 25,866,600\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 25,796,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt8OV8UpU-Yg",
        "colab_type": "code",
        "outputId": "ffe833ab-1e6f-4674-8c85-0c90b5006641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "\n",
        "# compile the model\n",
        "from time import time\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from keras.callbacks import TensorBoard\n",
        "# LOG_DIR=\"/root/logs\"\n",
        "# tensorboard = TensorBoard(log_dir=LOG_DIR.format(time()))\n",
        "\n",
        "optimizer = Adadelta(clipnorm = gradient_clipping_norm)\n",
        "model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "\n",
        "\n",
        "# train (fit) the model\n",
        "hist = model.fit([x_train['left'], x_train['right']], y_train, \n",
        "                 batch_size=64,\n",
        "                 epochs=n_epochs, \n",
        "                 validation_data=([x_validate['left'], x_validate['right']], y_validate))\n",
        "print(hist.history)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 283003 samples, validate on 121287 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0617 08:41:26.695863 140700723296128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            " 22144/283003 [=>............................] - ETA: 12:51 - loss: 0.2518 - acc: 0.6534"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lqahgzc2syH",
        "colab_type": "code",
        "outputId": "18b09f49-34c6-4285-9564-57d37844c8bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(2, datetime.timedelta(seconds=time()-training_start_time)))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-77ab6da39dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time finished.\\n{} epochs in {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtraining_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_start_time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_GQ1mRg20hM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}