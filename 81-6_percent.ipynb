{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQD_MAIN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohitDhungana/duplicate_question_detection/blob/master/81-6_percent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZlxkvW__7mI",
        "colab_type": "code",
        "outputId": "78517597-c999-42f1-d38e-0c17c1b2a632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        }
      },
      "source": [
        "from time import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import itertools\n",
        "import datetime\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVvNDvPLBLDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/train.csv')\n",
        "stops = set(stopwords.words('english'))\n",
        "\n",
        "def text_to_word_list(text):\n",
        "#   gets a whole question inside text variable on which  preprocessing is done and then the question is splitted into word indices and returned\n",
        "    text = str(text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    text = text.split()\n",
        "\n",
        "    return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6YQyhoHwdAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = dict() \n",
        "inverse_vocabulary = ['<unk>']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfmvHK6CBb2v",
        "colab_type": "code",
        "outputId": "d0b0dbc7-fc1a-4e5c-8f0a-4a5f69b7fdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Prepare embedding\n",
        "\n",
        "  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
        "word2vec = KeyedVectors.load_word2vec_format('/content/drive/My Drive/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
        "\n",
        "questions_cols = ['question1', 'question2']\n",
        "\n",
        "# Iterate over the questions(i.e. 'question 1', 'question2') of the training sets provided \n",
        "# get the data from dataset(df) in  variable dataset\n",
        "for dataset in [df]:\n",
        "#   now iterate through the rows of the dataset using  index as iterator (i.e. goes through the row having particular index at a time) \n",
        "    for index, row in dataset.iterrows():\n",
        "\n",
        "        # Iterate through the text of both questions within the current  row\n",
        "        for question in questions_cols:\n",
        "            que2no = []  # que2no ->  numbers representation of the cureently being processed question\n",
        "            \n",
        "            count_ = 0\n",
        "\n",
        "            for word in text_to_word_list(row[question]):\n",
        "\n",
        "                # Check for unwanted words i.e mainly stopwords\n",
        "                if word in stops and word not in word2vec.vocab:\n",
        "                    continue\n",
        "                    \n",
        "#                 limit the length to 50, this decreased the time to train an epoch from more than 1 hour to 20 minutes.\n",
        "                if count_ >= 50 :\n",
        "                  continue\n",
        "                count_ +=1\n",
        "                \n",
        "                \n",
        "                if word not in vocabulary:\n",
        "                    vocabulary[word] = len(inverse_vocabulary)\n",
        "                    que2no.append(len(inverse_vocabulary))\n",
        "                    inverse_vocabulary.append(word)\n",
        "                else:\n",
        "                    que2no.append(vocabulary[word])\n",
        "#                     que2no.append(float(vocabulary[word]))\n",
        "\n",
        "#                 que2no=list(map(int,que2no))\n",
        "\n",
        "            # Replace questions as word to question as number representation\n",
        "            dataset.set_value(index, question, que2no)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nLYjdBv3cPcI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "f79deb22-1441-4751-ca9d-ad62c0eb6f43"
      },
      "source": [
        "# max_sequence_length=50\n",
        "max_seq_length = max(df.question1.map(lambda x: len(x)).max(),\n",
        "                     df.question2.map(lambda x: len(x)).max()\n",
        "                    )\n",
        "# max_seq_length\n",
        "df.tail()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>404285</th>\n",
              "      <td>404285</td>\n",
              "      <td>433578</td>\n",
              "      <td>379845</td>\n",
              "      <td>[26, 184, 3632, 115, 307, 8, 3, 24585, 522, 52...</td>\n",
              "      <td>[26, 184, 3632, 115, 307, 8, 12032, 522, 523, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404286</th>\n",
              "      <td>404286</td>\n",
              "      <td>18840</td>\n",
              "      <td>155606</td>\n",
              "      <td>[97, 99, 2441, 307, 2, 598, 180, 1822]</td>\n",
              "      <td>[2, 47, 467, 77, 307, 2, 598, 180, 1822]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404287</th>\n",
              "      <td>404287</td>\n",
              "      <td>537928</td>\n",
              "      <td>537929</td>\n",
              "      <td>[1, 2, 57, 11012]</td>\n",
              "      <td>[1, 2, 83, 11012]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404288</th>\n",
              "      <td>404288</td>\n",
              "      <td>537930</td>\n",
              "      <td>537931</td>\n",
              "      <td>[1, 2, 3, 21205, 12587, 534, 2769, 33, 3114, 8...</td>\n",
              "      <td>[16, 42, 1086, 2877, 2854, 2622, 1220, 16, 173...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404289</th>\n",
              "      <td>404289</td>\n",
              "      <td>537932</td>\n",
              "      <td>537933</td>\n",
              "      <td>[1, 2, 139, 401, 2543, 175, 7227]</td>\n",
              "      <td>[1, 2, 47, 139, 401, 2543, 175, 135, 7227]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  ...  is_duplicate\n",
              "404285  404285  ...             0\n",
              "404286  404286  ...             1\n",
              "404287  404287  ...             0\n",
              "404288  404288  ...             0\n",
              "404289  404289  ...             0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS30hxt_OvzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 300\n",
        "# creating an embedding matrix whose length is one more than vocabulary and dimension is 300\n",
        "embedding_matrix = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  \n",
        "embedding_matrix[0] = 0  # So that the zeroth place remain empty \n",
        "\n",
        "# (Build the embedding matrix) Assigning the word2vec embedding for each words of our vocabulary  \n",
        "for word, index in vocabulary.items():\n",
        "    if word in word2vec.vocab:\n",
        "        embedding_matrix[index] = word2vec.word_vec(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d-Q0dSmTamb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZzmU3hmC1ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS7KaJt3O2R8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del word2vec\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLo86-66TcDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45RAsWjXC22L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQX5TXOPQYO",
        "colab_type": "code",
        "outputId": "c6bcd99c-3b87-4077-8620-b71dbb1af2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X=df[questions_cols]\n",
        "Y=df['is_duplicate']\n",
        "\n",
        "\n",
        "x_train,x_validate,y_train,y_validate = train_test_split(X, Y, test_size = 0.3) # dataset split to 70% for training and 30% for validation\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_validate.shape)\n",
        "print(y_train.shape)\n",
        "print(y_validate.shape)\n",
        "                 \n",
        "# Split to dicts\n",
        "x_train = {'left': x_train.question1, 'right': x_train.question2}\n",
        "x_validate = {'left': x_validate.question1, 'right': x_validate.question2}\n",
        "\n",
        "# Convert labels to their numpy representations\n",
        "y_train=y_train.values\n",
        "y_validate=y_validate.values\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(283003, 2)\n",
            "(121287, 2)\n",
            "(283003,)\n",
            "(121287,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwux50WlTd80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5tn7V2GC40y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZc4-nnYP-dL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# zero padding\n",
        "\n",
        "for dataset, side in itertools.product([x_train,x_validate],['left','right']):\n",
        "  dataset[side] = pad_sequences(dataset[side], maxlen = max_seq_length)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgUMIIWPQ3zc",
        "colab_type": "code",
        "outputId": "28d591bc-2b51-4035-8233-116731581924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# print(df['question1'][0])\n",
        "\n",
        "# print(dataset)\n",
        "print(x_train['left'].shape)\n",
        "# print(x_train['left'])\n",
        "print(x_validate['left'].shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(283003, 50)\n",
            "(121287, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhNvzgKuQ_nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check to see if shape of left and right input is same\n",
        "assert x_train['left'].shape == x_train['right'].shape\n",
        "\n",
        "# check to see if shape of input and output is same\n",
        "assert len(x_train['left']) == len(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7ox-AVGRu60",
        "colab_type": "code",
        "outputId": "2999a01a-f68a-4c07-e110-33698620325c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# shape of question1 column (x,y)==(total rows, total words in each question)\n",
        "x_train['left'].shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(283003, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz0P_YedR236",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# manhattan distance calculation function\n",
        "import tensorflow.keras.backend as K\n",
        "def manhattan_distance(left,right):\n",
        "  return K.exp(-K.sum(K.abs(left-right),axis=1, keepdims=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vdeYPxYTicf",
        "colab_type": "code",
        "outputId": "6b64a30d-a5bc-4557-f852-747ef4df7f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Lambda, CuDNNLSTM\n",
        "\n",
        "n_hidden = 15\n",
        "n_epochs=500\n",
        "gradient_clipping_norm  = 1.25\n",
        "\n",
        "# input layer\n",
        "#recheck shape before training\n",
        "left_input = Input(shape = (max_seq_length,), dtype='int32',name = 'left_input')\n",
        "right_input = Input(shape = (max_seq_length,), dtype='int32', name = 'right_input')\n",
        "\n",
        "\n",
        "\n",
        "# embedding layer\n",
        "# recheck dims \n",
        "embedding_layer = Embedding(input_dim = len(embedding_matrix), output_dim = embedding_dim, input_length = max_seq_length, weights=[embedding_matrix], trainable=False, name = 'embedding_layer')\n",
        "\n",
        "encoded_left = embedding_layer(left_input)\n",
        "encoded_right = embedding_layer(right_input)\n",
        "\n",
        "\n",
        "\n",
        "#LSTM instantiation\n",
        "# check parameter for LSTM.\n",
        "# LSTM(100, return_sequences=True, dropout=0.25, recurrent_dropout=0.1)\n",
        "shared_lstm = CuDNNLSTM(n_hidden, name = 'LSTM_layer')\n",
        "\n",
        "# shared LSTM\n",
        "left_output = shared_lstm(encoded_left)\n",
        "right_output = shared_lstm(encoded_right)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# TODO: check output shape of the output lambda layer\n",
        "# output layer\n",
        "output_layer = Lambda(function = lambda x : manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0],1))([left_output, right_output])\n",
        "\n",
        "\n",
        "\n",
        "# define above model\n",
        "model = tf.keras.Model(inputs=[left_input, right_input], outputs=output_layer)\n",
        "\n",
        "# summary of model\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0629 04:17:40.747349 140099933190016 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0629 04:17:43.723053 140099933190016 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "left_input (InputLayer)         [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "right_input (InputLayer)        [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_layer (Embedding)     (None, 50, 300)      25796400    left_input[0][0]                 \n",
            "                                                                 right_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "LSTM_layer (CuDNNLSTM)          (None, 15)           19020       embedding_layer[0][0]            \n",
            "                                                                 embedding_layer[1][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           LSTM_layer[0][0]                 \n",
            "                                                                 LSTM_layer[1][0]                 \n",
            "==================================================================================================\n",
            "Total params: 25,815,420\n",
            "Trainable params: 19,020\n",
            "Non-trainable params: 25,796,400\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nt8OV8UpU-Yg",
        "colab_type": "code",
        "outputId": "0015227e-f4f2-4b6a-a2b4-fc709153ae53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# compile the model\n",
        "from time import time\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "\n",
        "\n",
        "weight_path='/content/drive/My Drive/dqd_model_weights_80percent.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
        "callbacks = [checkpoint, early_stopping]\n",
        "\n",
        "optimizer = Adadelta(lr=1, clipnorm = gradient_clipping_norm)\n",
        "model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
        "\n",
        "# LOG_DIR=\"/root/logs\"\n",
        "# tensorboard = TensorBoard(log_dir=LOG_DIR.format(time()))\n",
        "\n",
        "# Start training\n",
        "training_start_time = time()\n",
        "\n",
        "\n",
        "# train (fit) the model\n",
        "hist = model.fit([x_train['left'], x_train['right']], y_train, \n",
        "                 batch_size=64,\n",
        "                 epochs=n_epochs, \n",
        "                 validation_split=0.2, \n",
        "                 callbacks=callbacks)\n",
        "print(hist.history)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 226402 samples, validate on 56601 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "W0629 04:17:44.311482 140099933190016 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.7428\n",
            "Epoch 00001: val_loss improved from inf to 0.16146, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 35s 154us/sample - loss: 0.1733 - acc: 0.7429 - val_loss: 0.1615 - val_acc: 0.7659\n",
            "Epoch 2/500\n",
            "225984/226402 [============================>.] - ETA: 0s - loss: 0.1564 - acc: 0.7747\n",
            "Epoch 00002: val_loss improved from 0.16146 to 0.15553, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 146us/sample - loss: 0.1564 - acc: 0.7747 - val_loss: 0.1555 - val_acc: 0.7746\n",
            "Epoch 3/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.7861\n",
            "Epoch 00003: val_loss improved from 0.15553 to 0.15043, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 145us/sample - loss: 0.1501 - acc: 0.7861 - val_loss: 0.1504 - val_acc: 0.7868\n",
            "Epoch 4/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.7939\n",
            "Epoch 00004: val_loss improved from 0.15043 to 0.14798, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1461 - acc: 0.7939 - val_loss: 0.1480 - val_acc: 0.7891\n",
            "Epoch 5/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.7990\n",
            "Epoch 00005: val_loss improved from 0.14798 to 0.14746, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1431 - acc: 0.7990 - val_loss: 0.1475 - val_acc: 0.7858\n",
            "Epoch 6/500\n",
            "225984/226402 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.8029\n",
            "Epoch 00006: val_loss improved from 0.14746 to 0.14535, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 144us/sample - loss: 0.1408 - acc: 0.8029 - val_loss: 0.1453 - val_acc: 0.7904\n",
            "Epoch 7/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.8072\n",
            "Epoch 00007: val_loss improved from 0.14535 to 0.14354, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1388 - acc: 0.8072 - val_loss: 0.1435 - val_acc: 0.7984\n",
            "Epoch 8/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.8101\n",
            "Epoch 00008: val_loss improved from 0.14354 to 0.14299, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1370 - acc: 0.8101 - val_loss: 0.1430 - val_acc: 0.8004\n",
            "Epoch 9/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.8124\n",
            "Epoch 00009: val_loss improved from 0.14299 to 0.14170, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1357 - acc: 0.8125 - val_loss: 0.1417 - val_acc: 0.7979\n",
            "Epoch 10/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.8149\n",
            "Epoch 00010: val_loss improved from 0.14170 to 0.14106, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 145us/sample - loss: 0.1344 - acc: 0.8149 - val_loss: 0.1411 - val_acc: 0.7993\n",
            "Epoch 11/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.8170\n",
            "Epoch 00011: val_loss improved from 0.14106 to 0.13980, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 149us/sample - loss: 0.1331 - acc: 0.8170 - val_loss: 0.1398 - val_acc: 0.8023\n",
            "Epoch 12/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.8186\n",
            "Epoch 00012: val_loss improved from 0.13980 to 0.13951, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1321 - acc: 0.8186 - val_loss: 0.1395 - val_acc: 0.8028\n",
            "Epoch 13/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.8203\n",
            "Epoch 00013: val_loss improved from 0.13951 to 0.13852, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1312 - acc: 0.8204 - val_loss: 0.1385 - val_acc: 0.8040\n",
            "Epoch 14/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.8219\n",
            "Epoch 00014: val_loss improved from 0.13852 to 0.13801, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1303 - acc: 0.8220 - val_loss: 0.1380 - val_acc: 0.8059\n",
            "Epoch 15/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.8231\n",
            "Epoch 00015: val_loss improved from 0.13801 to 0.13795, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 146us/sample - loss: 0.1295 - acc: 0.8231 - val_loss: 0.1380 - val_acc: 0.8081\n",
            "Epoch 16/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.8249\n",
            "Epoch 00016: val_loss improved from 0.13795 to 0.13719, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 145us/sample - loss: 0.1288 - acc: 0.8249 - val_loss: 0.1372 - val_acc: 0.8075\n",
            "Epoch 17/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.8258\n",
            "Epoch 00017: val_loss improved from 0.13719 to 0.13690, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1280 - acc: 0.8258 - val_loss: 0.1369 - val_acc: 0.8098\n",
            "Epoch 18/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.8271\n",
            "Epoch 00018: val_loss improved from 0.13690 to 0.13666, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 145us/sample - loss: 0.1275 - acc: 0.8271 - val_loss: 0.1367 - val_acc: 0.8086\n",
            "Epoch 19/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.8277\n",
            "Epoch 00019: val_loss improved from 0.13666 to 0.13624, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 148us/sample - loss: 0.1269 - acc: 0.8277 - val_loss: 0.1362 - val_acc: 0.8101\n",
            "Epoch 20/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.8285\n",
            "Epoch 00020: val_loss did not improve from 0.13624\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1264 - acc: 0.8286 - val_loss: 0.1365 - val_acc: 0.8101\n",
            "Epoch 21/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.8299\n",
            "Epoch 00021: val_loss did not improve from 0.13624\n",
            "226402/226402 [==============================] - 32s 140us/sample - loss: 0.1258 - acc: 0.8300 - val_loss: 0.1366 - val_acc: 0.8072\n",
            "Epoch 22/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.8308\n",
            "Epoch 00022: val_loss improved from 0.13624 to 0.13608, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 146us/sample - loss: 0.1254 - acc: 0.8308 - val_loss: 0.1361 - val_acc: 0.8090\n",
            "Epoch 23/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.8308\n",
            "Epoch 00023: val_loss improved from 0.13608 to 0.13550, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 149us/sample - loss: 0.1250 - acc: 0.8308 - val_loss: 0.1355 - val_acc: 0.8120\n",
            "Epoch 24/500\n",
            "226112/226402 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.8313\n",
            "Epoch 00024: val_loss did not improve from 0.13550\n",
            "226402/226402 [==============================] - 33s 144us/sample - loss: 0.1246 - acc: 0.8313 - val_loss: 0.1358 - val_acc: 0.8098\n",
            "Epoch 25/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.8322\n",
            "Epoch 00025: val_loss improved from 0.13550 to 0.13547, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1242 - acc: 0.8321 - val_loss: 0.1355 - val_acc: 0.8118\n",
            "Epoch 26/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.8330\n",
            "Epoch 00026: val_loss improved from 0.13547 to 0.13472, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 148us/sample - loss: 0.1238 - acc: 0.8330 - val_loss: 0.1347 - val_acc: 0.8133\n",
            "Epoch 27/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.8339\n",
            "Epoch 00027: val_loss did not improve from 0.13472\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1235 - acc: 0.8339 - val_loss: 0.1357 - val_acc: 0.8133\n",
            "Epoch 28/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.8342\n",
            "Epoch 00028: val_loss improved from 0.13472 to 0.13459, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 151us/sample - loss: 0.1231 - acc: 0.8342 - val_loss: 0.1346 - val_acc: 0.8138\n",
            "Epoch 29/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.8346\n",
            "Epoch 00029: val_loss improved from 0.13459 to 0.13426, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 150us/sample - loss: 0.1228 - acc: 0.8346 - val_loss: 0.1343 - val_acc: 0.8146\n",
            "Epoch 30/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.8354\n",
            "Epoch 00030: val_loss did not improve from 0.13426\n",
            "226402/226402 [==============================] - 33s 148us/sample - loss: 0.1224 - acc: 0.8354 - val_loss: 0.1345 - val_acc: 0.8122\n",
            "Epoch 31/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.8355\n",
            "Epoch 00031: val_loss did not improve from 0.13426\n",
            "226402/226402 [==============================] - 32s 141us/sample - loss: 0.1221 - acc: 0.8355 - val_loss: 0.1345 - val_acc: 0.8132\n",
            "Epoch 32/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.8358\n",
            "Epoch 00032: val_loss improved from 0.13426 to 0.13401, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1219 - acc: 0.8358 - val_loss: 0.1340 - val_acc: 0.8139\n",
            "Epoch 33/500\n",
            "226112/226402 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.8367\n",
            "Epoch 00033: val_loss did not improve from 0.13401\n",
            "226402/226402 [==============================] - 33s 144us/sample - loss: 0.1216 - acc: 0.8367 - val_loss: 0.1340 - val_acc: 0.8137\n",
            "Epoch 34/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.8371\n",
            "Epoch 00034: val_loss did not improve from 0.13401\n",
            "226402/226402 [==============================] - 32s 141us/sample - loss: 0.1214 - acc: 0.8372 - val_loss: 0.1343 - val_acc: 0.8125\n",
            "Epoch 35/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.8376\n",
            "Epoch 00035: val_loss improved from 0.13401 to 0.13389, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1211 - acc: 0.8376 - val_loss: 0.1339 - val_acc: 0.8146\n",
            "Epoch 36/500\n",
            "225984/226402 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.8374\n",
            "Epoch 00036: val_loss improved from 0.13389 to 0.13364, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1209 - acc: 0.8374 - val_loss: 0.1336 - val_acc: 0.8144\n",
            "Epoch 37/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.8384\n",
            "Epoch 00037: val_loss improved from 0.13364 to 0.13333, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 150us/sample - loss: 0.1206 - acc: 0.8385 - val_loss: 0.1333 - val_acc: 0.8151\n",
            "Epoch 38/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.8389\n",
            "Epoch 00038: val_loss did not improve from 0.13333\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1203 - acc: 0.8388 - val_loss: 0.1334 - val_acc: 0.8152\n",
            "Epoch 39/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.8390\n",
            "Epoch 00039: val_loss improved from 0.13333 to 0.13317, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 148us/sample - loss: 0.1201 - acc: 0.8389 - val_loss: 0.1332 - val_acc: 0.8159\n",
            "Epoch 40/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.8396\n",
            "Epoch 00040: val_loss improved from 0.13317 to 0.13309, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 34s 150us/sample - loss: 0.1200 - acc: 0.8396 - val_loss: 0.1331 - val_acc: 0.8153\n",
            "Epoch 41/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.8395\n",
            "Epoch 00041: val_loss did not improve from 0.13309\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1197 - acc: 0.8395 - val_loss: 0.1332 - val_acc: 0.8159\n",
            "Epoch 42/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.8400\n",
            "Epoch 00042: val_loss did not improve from 0.13309\n",
            "226402/226402 [==============================] - 32s 141us/sample - loss: 0.1196 - acc: 0.8400 - val_loss: 0.1333 - val_acc: 0.8153\n",
            "Epoch 43/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.8404\n",
            "Epoch 00043: val_loss did not improve from 0.13309\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1193 - acc: 0.8404 - val_loss: 0.1332 - val_acc: 0.8156\n",
            "Epoch 44/500\n",
            "226112/226402 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.8408\n",
            "Epoch 00044: val_loss did not improve from 0.13309\n",
            "226402/226402 [==============================] - 32s 140us/sample - loss: 0.1191 - acc: 0.8408 - val_loss: 0.1331 - val_acc: 0.8146\n",
            "Epoch 45/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.8412\n",
            "Epoch 00045: val_loss improved from 0.13309 to 0.13288, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1188 - acc: 0.8412 - val_loss: 0.1329 - val_acc: 0.8152\n",
            "Epoch 46/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.8418\n",
            "Epoch 00046: val_loss did not improve from 0.13288\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1187 - acc: 0.8418 - val_loss: 0.1330 - val_acc: 0.8164\n",
            "Epoch 47/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.8425\n",
            "Epoch 00047: val_loss improved from 0.13288 to 0.13272, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1185 - acc: 0.8424 - val_loss: 0.1327 - val_acc: 0.8161\n",
            "Epoch 48/500\n",
            "226048/226402 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.8420\n",
            "Epoch 00048: val_loss did not improve from 0.13272\n",
            "226402/226402 [==============================] - 32s 144us/sample - loss: 0.1183 - acc: 0.8420 - val_loss: 0.1328 - val_acc: 0.8167\n",
            "Epoch 49/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.8424\n",
            "Epoch 00049: val_loss improved from 0.13272 to 0.13252, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 147us/sample - loss: 0.1182 - acc: 0.8425 - val_loss: 0.1325 - val_acc: 0.8160\n",
            "Epoch 50/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.8428\n",
            "Epoch 00050: val_loss did not improve from 0.13252\n",
            "226402/226402 [==============================] - 32s 144us/sample - loss: 0.1179 - acc: 0.8428 - val_loss: 0.1330 - val_acc: 0.8148\n",
            "Epoch 51/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.8432\n",
            "Epoch 00051: val_loss improved from 0.13252 to 0.13251, saving model to /content/drive/My Drive/dqd_model_weights_80percent.h5\n",
            "226402/226402 [==============================] - 33s 145us/sample - loss: 0.1178 - acc: 0.8431 - val_loss: 0.1325 - val_acc: 0.8170\n",
            "Epoch 52/500\n",
            "226240/226402 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.8434\n",
            "Epoch 00052: val_loss did not improve from 0.13251\n",
            "226402/226402 [==============================] - 32s 142us/sample - loss: 0.1177 - acc: 0.8434 - val_loss: 0.1327 - val_acc: 0.8167\n",
            "Epoch 53/500\n",
            "226176/226402 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.8439\n",
            "Epoch 00053: val_loss did not improve from 0.13251\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1174 - acc: 0.8439 - val_loss: 0.1327 - val_acc: 0.8163\n",
            "Epoch 54/500\n",
            "226304/226402 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.8442\n",
            "Epoch 00054: val_loss did not improve from 0.13251\n",
            "226402/226402 [==============================] - 32s 141us/sample - loss: 0.1172 - acc: 0.8442 - val_loss: 0.1330 - val_acc: 0.8162\n",
            "Epoch 55/500\n",
            "226112/226402 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.8440\n",
            "Epoch 00055: val_loss did not improve from 0.13251\n",
            "226402/226402 [==============================] - 32s 143us/sample - loss: 0.1171 - acc: 0.8440 - val_loss: 0.1328 - val_acc: 0.8153\n",
            "Epoch 56/500\n",
            "226368/226402 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.8447\n",
            "Epoch 00056: val_loss did not improve from 0.13251\n",
            "226402/226402 [==============================] - 31s 139us/sample - loss: 0.1170 - acc: 0.8447 - val_loss: 0.1325 - val_acc: 0.8173\n",
            "{'loss': [0.17328771529716355, 0.15640993496580097, 0.150113967967702, 0.1461329400376698, 0.14314230786120843, 0.1408058929145181, 0.13880574807352636, 0.13702716671884801, 0.13566152739282739, 0.13436111970885464, 0.1331392469477453, 0.13210124587231523, 0.13115384462898033, 0.13026591848597727, 0.12948914465749192, 0.12877972354882683, 0.12804962065208064, 0.1274525306608743, 0.12693456109518436, 0.1264274691647078, 0.12581604190688814, 0.12544231149048488, 0.12500528175812245, 0.12455798853351815, 0.12419581924708709, 0.1238192644074012, 0.12345303144033494, 0.1231051086984552, 0.12276016915954245, 0.12243111822586146, 0.12212587901091547, 0.12187525590059335, 0.12155615775169219, 0.12140240675113491, 0.12108464890067712, 0.12085602489993942, 0.12063700374844034, 0.12029310882909236, 0.12014889526903309, 0.11996306382238982, 0.11971173935443642, 0.1195526583590047, 0.11933315473375655, 0.11911935129846653, 0.11883199085038341, 0.11870591196874554, 0.11852034501406061, 0.11830686942722127, 0.11817015038644584, 0.11793609761655546, 0.11776818215874395, 0.11767073097634417, 0.11744857586387075, 0.117203412255285, 0.11709328363267849, 0.11696993814357823], 'acc': [0.7428645, 0.7746619, 0.7861238, 0.79394174, 0.7990168, 0.80286396, 0.8072146, 0.81012535, 0.81250167, 0.8149442, 0.81699365, 0.8186456, 0.82035494, 0.82198477, 0.8230978, 0.8249088, 0.82575685, 0.8270863, 0.8277489, 0.8285616, 0.82998824, 0.8307701, 0.8308275, 0.83127356, 0.83213043, 0.83302706, 0.8338707, 0.83418876, 0.8345553, 0.8353592, 0.8354873, 0.8357965, 0.8366799, 0.8371525, 0.83761185, 0.8373866, 0.83847314, 0.83883536, 0.8389281, 0.8396039, 0.83951116, 0.84001464, 0.84042984, 0.8408053, 0.8412293, 0.8418168, 0.84244394, 0.84197575, 0.8424528, 0.8427885, 0.84314185, 0.8433627, 0.8438927, 0.8442284, 0.84399873, 0.8446745], 'val_loss': [0.16145570417730692, 0.15553401058460406, 0.1504281522310165, 0.147976335584912, 0.1474589558809217, 0.14534510196211464, 0.14354041907897833, 0.14299304764797127, 0.14170313234984316, 0.14105726831529156, 0.13979940392888227, 0.13950897471661727, 0.13852123525777205, 0.1380093666611475, 0.13795097805021914, 0.1371876331383962, 0.13689875546830638, 0.13665613585009287, 0.13624134238514027, 0.13653828411263963, 0.1365672830728606, 0.13607885041367837, 0.13549664094316202, 0.13576382614457752, 0.13547264817101115, 0.13471789008011356, 0.13567440423728977, 0.13458969927565356, 0.1342621350811344, 0.13452777708658883, 0.13452015019914682, 0.13400804943178962, 0.1340203212347682, 0.13430055172924094, 0.13388849898960326, 0.1336361720916612, 0.13333335057435672, 0.13335675952932682, 0.1331707589364225, 0.13309258335995272, 0.13319633827931077, 0.13327803731815538, 0.13317650760148508, 0.13312005446029046, 0.13288215136037707, 0.13297432961470204, 0.13271532676895104, 0.13279750817184433, 0.1325226662888257, 0.13296618246846403, 0.13251262823878066, 0.13273937683676568, 0.1326663372504564, 0.13296603709835778, 0.13282326230568775, 0.13253544644515142], 'val_acc': [0.76586986, 0.7746153, 0.78680587, 0.7890673, 0.78578115, 0.79035705, 0.7983781, 0.80035686, 0.79793644, 0.7992615, 0.802265, 0.802848, 0.8040494, 0.80592215, 0.8080776, 0.8075299, 0.8098267, 0.8085546, 0.8100917, 0.8101094, 0.80719423, 0.8089963, 0.81196445, 0.8098444, 0.8118231, 0.8132895, 0.81332487, 0.81383723, 0.8145969, 0.81222945, 0.8131835, 0.81390786, 0.8137312, 0.81251216, 0.8145616, 0.8144026, 0.81507397, 0.8151976, 0.81593966, 0.81533897, 0.81592196, 0.8152859, 0.8156216, 0.81463224, 0.8152153, 0.81638134, 0.81609863, 0.8166993, 0.816028, 0.8147559, 0.81698203, 0.8166817, 0.81625766, 0.8161517, 0.81533897, 0.8172824]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lqahgzc2syH",
        "colab_type": "code",
        "outputId": "6fae79c7-783e-4be7-e89e-1c3381176e09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "source": [
        "print(\"Training time finished.\\n{} epochs in {}\".format(2, datetime.timedelta(seconds=time()-training_start_time)))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.savefig(\"abc76.png\")\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.savefig(\"bc76.png\")\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training time finished.\n",
            "2 epochs in 0:30:37.740247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/8wB6PlAxT/CAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiBJzpPvc9vT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZJLzbN2cZLU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "model.save('/content/drive/My Drive/DQD.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5MSuV07lYEM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dfc76b55-3299-4afe-f764-bdb58172e71f"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/DQD.h5')\n",
        "score, acc = model.evaluate([x_validate['left'], x_validate['right']], y_validate, batch_size=64)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "121287/121287 [==============================] - 8s 66us/sample - loss: 0.1326 - acc: 0.8164\n",
            "Test score: 0.13261363475199492\n",
            "Test accuracy: 0.81639415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL1cPtI2lq7Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}